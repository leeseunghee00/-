# demand_forecasting 🚲
## ▣ 따릉이 대여소별 대여량 반납량 예측을 통한 반납 대여소 서비스 : 여기 따릉이 대 (여따대)

### ※ 본격적인 대여량, 반납량 예측 모형을 만들기 앞서서 대략적인 대여, 반납 추이를 보기 위한 데이터분석

### 1. 대여반납 추이 알아보기 (함수 Create_Bike_Plot(bike_df,name) 사용)

- bike_df : 저장한 월별 공공자전거 대여이력 정보 데이터프레임 입력
- name : 그래프로 알아보고 싶은 대여소 이름 입력

#### ▷ raw 데이터 : 공공자전거 대여이력 정보_202006.csv 

- 공공자전거 대여이력 정보_202005.csv 와 같이 월을 바꾸면 다른 월의 데이터로도 가능

- 자전거 이동 경로에 따른 대여 대여소, 대여시간, 반납 대여소, 반납시간 열로 이루어져 있음

#### ▷ 분석 결과 : 입력한 대여소의 시간별(0시-23시) 대여량, 반납량, 대여-반납 그래프

#### ▷ 분석 목적 : 대여소별로 시간별로 대여, 반납량이 어떻게 다른지 알기 위해 그래프를 그려봄

- 추후 대여, 반납량 예측모형이 필요한 대여소를 선정시 참고로 사용가능

<br>

### 2. 추가배치 요청건수 데이터 분석

#### ▷ raw 데이터 : 정보공개창구에 요청하여 21년에 새로 생긴 따릉이 서비스인 추가배치요청에 대한 데이터를 청구함
- 21년 1월 1일부터 8월 8일까지 요청일자에 따라 요청이 들어온 대여소와 하루 동안 요청건수가 들어온 횟수에 대한 데이터
- 요청일자, 대여소명, 신청합계 컬럼으로 이루어져 있음

#### 1) (대여소 구분없이)일별 추가배치 요청건수 데이터
- 이용한 데이터 : 정보공개답변서일별.csv
- 일별요청건수가 최대인 날짜 확인 : 2021-06-16

#### 2) 대여소별 추가배치요청건수 데이터
- 이용한 데이터 : 정보공개답변서.csv
- 대여소별 요청건수 합계가 최대인 대여소 확인 : 상왕십리역 1번출구
- 데이터프레임을 보면 '한양수자인아파트 앞' 이라는 이름이 동일한 대여소가 2개가 있다는 것을 알고 제외함

#### 3) 추가배치 요청건수 합계 top500
- top500 : 대여소별 요청건수 합계가 110이상 261이하인 대여소

<br>

### 3. 대여량, 반납량이 많은 대여소 찾기 

#### ▷ raw 데이터 : 공공자전거 대여소별 이용정보 17년부터 21년까지 월별 대여, 반납 내역
- 대여 반납 내역이 모두 있는 날짜는 17년 01월부터 20년 06월까지로 그 기간동안의 내역으로만 데이터처리함.
- 합계로 안하고 월 평균으로 한 이유 : 대여소가 계속 새로 생겨 나기 때문에 평균으로 해서 객관성을 높임.
- 서울특별시 공공자전거 대여소별 이용정보(월간)_2017_1_12.csv
- 서울특별시 공공자전거 대여소별 이용정보(월간)_2018_1_6.csv
- 대여소별 대여정보_201807_11.csv
- 공공자전거 대여소별 이용정보_201812_201905_대여.csv
- 공공자전거 대여소별 이용정보_201812_201905_반납.csv
- 공공자전거 대여소별 이용정보_201906_201911_대여.csv
- 공공자전거 대여소별 이용정보_201906_201911_반납.csv
- 공공자전거 대여소별 이용정보_201912_202005_대여.csv
- 공공자전거 대여소별 이용정보_201912_202005_반납.csv
- 공공자전거 대여소별 이용정보_202006_대여.csv
- 공공자전거 대여소별 이용정보_202006_반납.csv

#### 1) 대여량 높은 대여소 알아보기
- 총 데이터를 쉽게 concat 하기 위해 사용자 정의함수 data_pretreatment_rent(df) 사용
- 모든 데이터를 대여소명, 대여일자, 대여건수 컬럼으로 바꾸어 concat 진행
- 대여소별로 groupby.mean() 하여 대여소별 월별 대여량 평균 데이터 얻음 
- 월별 대여량 평균 top500

#### 2) 반납량 높은 대여소 알아보기
- 총 데이터를 쉽게 concat 하기 위해 사용자 정의함수 data_pretreatment_return(df) 사용
- 모든 데이터를 대여소명, 반납일자, 반납건수 컬럼으로 바꾸어 concat 진행
- 대여소별로 groupby.mean() 하여 대여소별 월별 반납량 평균 데이터 얻음 
- 월별 반납량 평균 top500

#### 3) 대여소의 대여 반납내역의 양에 따라 분류하기
① 대여량 월 평균도 높고 반납량 월 평균도 높은 대여소(Type mean_A) : 466개 <br>
② 월 평균 대여량은 높은데 월 평균 반납량은 높지 않은 대여소(Type mean_B) : 자전거를 보충할 필요가 있는 대여소 : 32개 <br>
③ 월 평균 반납량은 높은데 월 평균 대여량은 높지 않은 대여소(Type mean_C) : 32개 

#### 4) 대여가 높고 반납이 적은 대여소(Type mean_B)들이 추가배치요청을 받았는지 알아보기
- 월 평균 대여량은 높은데 월 평균 반납량은 높지 않은 대여소(Type mean_B)와 추가배치요청건수가 많이된 대여소들의 교집합 : 11개

<br>
<br>

### ※ 대여량 반납량 예측모형을 위한 데이터셋 만들기
### 1. 대여소별 년,월,일,시간,요일 별 대여량 데이터셋, 반납량 데이터셋 만들기
#### ▷ raw 데이터 : 공공자전거 대여이력 정보
- 공공자전거 대여이력 정보_202001.csv
- 공공자전거 대여이력 정보_202002.csv
- 공공자전거 대여이력 정보_202003.csv
- 공공자전거 대여이력 정보_202004.csv
- 공공자전거 대여이력 정보_202005.csv
- 공공자전거 대여이력 정보_202006.csv
- 공공자전거 대여이력 정보_202007_08.csv
- 공공자전거 대여이력 정보_202009.csv
- 공공자전거 대여이력 정보_202010.csv
- 공공자전거 대여이력 정보_202011.csv
- 공공자전거 대여이력 정보_202012.csv
- 대여소마다 공동 요인 : 년, 월, 일, 시간, 요일
#### ▷ 데이터셋 생성과정
1) 시간대별 대여량 데이터 만들기 (raw 데이터가 이어져 있는 7,8월 제외하고 한번에 처리)
2) 시간대별 반납량 데이터 만들기 (raw 데이터가 이어져 있는 7,8월 제외하고 한번에 처리)
#### ▷ 전처리 후 데이터
- rent_202001.csv 형식으로 1월부터 12월 까지 12개 데이터
- - Unnamed: 0, 보관소명, 년, 월, 일, 요일, 시간, 대여량 열로 구성
- return_202001.csv 형식으로 1월부터 12월까지 12개 데이터
- - Unnamed: 0, 보관소명, 년, 월, 일, 요일, 시간, 반납량 열로 구성

<br>

### 2. 대여량 및 반납량에 영향을 줄 것으로 예상되는 요인
### 1) 요인1 : 날씨 
### ① 평균기온 + ② 강수 및 적설
#### ▷ raw 데이터 : 일별 기온 데이터, 구별 시간별 기온 데이터, 일별 강수 데이터, 구별 시간별 강수 데이터
- 날씨_기온.csv, 날씨_강수적설.csv : 일별 기온, 강수 데이터(시간별로 차이없음)
- OBS_기온.csv, OBS_강수.csv : 구별 시간별로 측정한 기온, 강수 데이터
- 날씨 데이터의 범위 : 2020년 전체
#### ▷ 데이터셋 생성과정
1) 일별 기온, 강수 데이터 보이고 구별 시간별 기온, 강수 데이터 전처리
2) 전처리된 대여반납 데이터에 일별 기온, 강수 데이터 넣기 : 사용자 정의함수 weather_te_ra 사용
3) 기온, 강수의 구별 시간별 데이터 넣기 : 사용자 정의함수 weather_tera 사용

- 구별 시간별 기온, 강수 데이터가 모든 시간에 대한 데이터가 없고 랜덤으로 데이터가 빠져있음
- 따라서 일별 데이터를 먼저 넣고 구별 시간별 데이터를 새로운 열로 저장
- 새로 저장한 구별 시간별 데이터에서 시간별 데이터값이 없는 기온, 강수 수치에 해당날짜의 일별 데이터로 채워넣음 
#### ▷ 전처리 후 데이터
- 사용자 정의함수 weather_te_ra 사용시
- - rent_te_ra_202001.csv 형식으로 1월부터 12월까지 12개 데이터
- - 보관소명, 년, 월, 일, 요일, 시간, 대여량, 기온, 강수 열로 구성
- - return_te_ra_202001.csv 형식으로 1월부터 12월까지 12개 데이터
- - 보관소명, 년, 월, 일, 요일, 시간, 반납량, 기온, 강수 열로 구성
- 사용자 정의함수 weather_tera 사용시
- - rent_tera_202001.csv 형식으로 1월부터 12월까지 12개 데이터
- - 보관소명, 년, 월, 일, 요일, 시간, 대여량, 구, 기온, 강수 열로 구성
- - return_tera_202001.csv 형식으로 1월부터 12월까지 12개 데이터
- - 보관소명, 년, 월, 일, 요일, 시간, 반납량, 구, 기온, 강수 열로 구성

<br>

### ③ 미세먼지와 초미세먼지
#### ▷ raw 데이터 : 구별 미세먼지, 초미세먼지 데이터, 대여소별 구 정보데이터
- 날씨_미세먼지_초미세먼지.csv : 미세먼지, 초미세먼지 구별 1년 데이터
- 공공자전거 대여소 정보_21.06.csv : 대여소별 구 정보데이터
#### ▷ 데이터셋 생성과정
1) 미세먼지, 초미세먼지 구별 1년 데이터 불러오기
2) 대여소별 구 데이터 불러오기
3) 구별 1년 미세먼지, 초미세먼지 데이터 + 대여소별 구 정보 합치기
4) 전처리된 대여, 반납 데이터에 미세먼지 데이터를 추가 : 사용자 정의함수 weather_dust 사용 
- - 전처리된 대여, 반납 데이터는 기온,강수 요소까지 합쳐진 데이터
#### ▷ 전처리 후 데이터
- bikename+dust.csv : 구별 1년 미세먼지, 초미세먼지 데이터 + 대여소별 구 데이터 merge한 데이터
- 사용자 정의함수 weather_dust 사용시
- - rent_dust_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 대여량, 구, 기온, 강수, 미세먼지(㎍/㎥), 초미세먼지(㎍/㎥) 열로 구성
- - return_dust_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 반납량, 구, 기온, 강수, 미세먼지(㎍/㎥), 초미세먼지(㎍/㎥) 열로 구성

<br>

### 2) 요인2 인구
### ① 유입인구 
#### ▷ raw 데이터 : 일별 시간별 전연령 서울 관내이동 인구데이터, 행정동별 코드 데이터, 대여소별 구 정보데이터
- INNER_PEOPLE_20200101.csv 형식으로 366개 : 일별 시간별 전연령 서울 관내이동 인구데이터
- 행정구역표.csv : 행정동별 코드 데이터
- 공공자전거 대여소 정보_21.06.csv : 대여소별 구 정보데이터
#### ▷ 데이터셋 생성과정
1) 일별데이터 전처리 : 사용자 정의함수 inner_small() 사용
- - "*" 값을 0으로 수정, 기준일(대여일자), 시간, 행정동코드로 groupby.sum()
- - 해당 시간에 해당 구의 유입인구 모두 합하여 정리
- - 기준일열에서 split 하여 년, 월, 일, 시간 열을 생성
2) 월별로 파일 합치기 : 사용자 정의함수 concat_inner(mon) 사용
3) 표준 행정구역별 행정동코드 데이터에서 행정동코드 10자리에서 8자리로 줄임 : 인구 데이터의 행정동코드가 8자리 이기때문
4) 행정구를 고려한 월별 유입인구 데이터셋 만들기 : 사용자 정의함수 merge_month() 사용
- - 유입인구 데이터가 행정동코드만 있기 때문에 해당 행정동코드가 어떤 구에 해당하는지 데이터셋 만들기
5) 따릉이 대여소 별 유입인구 데이터셋 만들기 : 사용자 정의함수 bikename_inner_merge() 사용
- - 대여소별 구 정보데이터와 구별 유입인구 데이터를 합침

#### ▷ 전처리 후 데이터
- 사용자 정의함수 inner_small() 사용시
- - inner_20200101.csv 형식으로 1월 1일부터 12월 31일까지 366개 데이터
- 사용자 정의함수 concat_inner(mon) 사용시
- - inner202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- 행정구역표.csv의 행정구역코드 8자리로 줄임 : new행정구역표.csv로 저장
- 사용자 정의함수 merge_month() 사용시
- - innerData202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 년, 월, 일, 시간, 구별 유입인구 열로 구성
- 사용자 정의함수 bikename_inner_merge() 사용시
- - bike_inner202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 시간, 구, 유입인구 열로 구성

<br>

### ① 생활인구
#### ▷ raw 데이터 : 월별 시간별 전연령 서울 생활인구 인구데이터, new행정동별 코드 데이터, 대여소별 구 정보데이터
- LOCAL_PEOPLE_DONG_202001.csv 형식으로 12개 : 월별 시간별 전연령 서울 생활인구 인구데이터
- new행정구역표.csv : 8자리로 줄인 행정동별 코드 데이터
- 공공자전거 대여소 정보_21.06.csv : 대여소별 구 정보데이터
#### ▷ 데이터셋 생성과정
1) 월별 데이터를 전처리 : 사용자 정의 함수 LifeNum(mon) 사용 
- - 기준일(대여일자), 시간대구분(시간), 구로 groupby.sum()
- - 해당 시간에 해당 구의 생활인구 모두 합하여 정리
- - 기준일열에서 split 하여 년, 월, 일, 시간 열을 생성
2) 따릉이 대여소 별 생활인구 데이터 만들기 : 사용자 정의함수 bikename_life_merge() 사용
- - 대여소별 구 정보데이터와 구별 생활인구 데이터를 합침

#### ▷ 전처리 후 데이터
- 사용자 정의함수 LifeNum(mon) 사용시
- - lifeData202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- 사용자 정의함수 bikename_life_merge() 사용시
- - bike_life202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 시간, 구, 생활인구 열로 구성

<br>

#### ③ 인구 데이터 모두 합침
- 전처리된 대여, 반납 데이터에 유입, 생활인구 데이터를 추가: 사용자 정의함수 bike_people() 사용
- - 전처리된 대여, 반납 데이터는 미세먼지 요소까지 합쳐진 데이터
#### ▷ 전처리 후 데이터
- 사용자 정의함수 bike_people() 사용시
- - rent_life_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 대여량, 구, 기온, 강수, 미세먼지(㎍/㎥), 초미세먼지(㎍/㎥), 총유입인구, 총생활인구수 열로 구성
- - return_life_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 반납량, 구, 기온, 강수, 미세먼지(㎍/㎥), 초미세먼지(㎍/㎥), 총유입인구, 총생활인구수 열로 구성

<br>

### 3) 요인3 : 지하철
#### ▷ raw 데이터 : 지하철 1-8호선의 역별, 월별, 일별, 시간별 승,하차인원 데이터, 자전거 대여소 별 지하철 역까지 거리 데이터
- train_station2.csv : 서울공공데이터 포털의 지하철역 정보데이터
- 서울교통공사 2020년 일별 시간대별 역별 승하차 인원(1_8호선).csv : 지하철 1-8호선의 역별, 월별, 일별, 시간별 승,하차인원 데이터
- 자전거_대여소_정보.csv : 따릉이의 대여소별 자전거 수 API를 이용하여 얻은 대여소 위도 경도 데이터
- distance : 자전거 대여소 별로 가장 가까운 지하철 역 간 거리가 300m이하인 대여소 데이터
- - QGIS 프로그램을 이용하여 직선거리가 300m 이하인 자전거 대여소와 역에 대한 데이터를 생성함

<br>

#### ▷ 데이터셋 생성과정
1) 데이터 적재 및 전처리
- - distance.csv 와 자전거_대여소_정보.csv를 merge 하여 자전거 대여소ID, 거리, 300m 이내에 있는 역명, 호선의 데이터로 전처리
2) 역별 일별 시간별 승하차 인구데이터셋 만들기
- - 서울교통공사 2020년 일별 시간대별 역별 승하차 인원(1_8호선).csv 에서 역별 시간별로 승차, 하차인원을 분류
- - 승차, 하차 데이터에서 년월일 데이터 프레임 만들기 : 사용자 정의함수 split_date(df) 사용
3) 지하철_승차, 지하철_하차 데이터와 승차_time, 하차_time 데이터셋 재조합 : 사용자 정의함수 MakeFinalTrainData 사용
- - train에 승하차 정보, time에 시간대 정보를 받아 start행 부터 end행까지의 승하차 정보와 시간대 정보를 매칭시키는 함수, use_type은 (승차, 하차)중 하나의 값이 들어감
4) 역별 시간별 승차 또는 하차 데이터 합치기 : 사용자 정의함수 MakeFinalTrainData(train, time, use_type) 사용
- - train에 승하차 정보, time에 시간대 정보를 받아 globals()함수로 여러변수를 만들어 MakeConcatDate함수로 만든 데이터 프레임을 각각 저장하고 concat을 이용하여 하나의 데이터프레임으로 재결합해주는 함수, use_type은 (승차, 하차)중 하나의 값이 들어감
5) 따릉이 대여소 정보 데이터와  승차인원, 하차인원 데이터를 지하철 역명과 호선을 key값으로 merge
- - 결측치는 시간은 0이 존재하므로 99로 나머지 수치값은 0으로 대체
6) 전처리된 대여, 반납 데이터에 유입, 생활인구 데이터를 추가: 사용자 정의함수 sub_people() 사용
- - 전처리된 대여, 반납 데이터는 유입, 생활인구 요소까지 합쳐진 데이터

<br>

#### ▷ 전처리 후 데이터
- train_station2.csv : kakao API를 사용하여 알아낸 서울특별시 내의 지하철역의 위도경도를 포함한 지하철역 정보데이터
- distance.csv : QGIS를 사용하여 따릉이 대여소와 지하철역간의 거리를 파악한 데이터 
- bike_train_distance : train_station2, 자전거_대여소_정보, distance 데이터들을 merge를 활용하여 가깝다고 생각되는 대여소와 지하철역을 매칭시킴
- 지하철_승차최종.csv : 보관소명, 보관소ID, 역명, 호선, 지하철_승차인원, 시간, 년, 월, 일 열로 구성
- 지하철_하차최종.csv : 보관소명, 보관소ID, 역명, 호선, 지하철_하차인원, 시간, 년, 월, 일 열로 구성
- 사용자 정의함수 sub_people() 사용시
- - rent_last_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 대여량, 구, 기온, 강수, 미세먼지, 초미세먼지, 총유입인구, 총생활인구, 지하철_하차인원 열로 구성
- - return_last_202001.csv 형식으로 1월부터 12월까지 12개 데이터 저장
- - 보관소명, 년, 월, 일, 요일, 시간, 반납량, 구, 기온, 강수, 미세먼지, 초미세먼지, 총유입인구, 총생활인구, 지하철_승차인원 열로 구성

<br>

### 3. 최종 데이터셋
#### - 대여소별 년, 월, 일 ,시간, 요일에 따라 달라지는 대여량과 반납량을 예측하기 위해 날씨, 인구, 지하철 요인이 합쳐진 데이터
#### - 대여량을 예측하기 위한 데이터셋과 반납량을 예측하기 위한 데이터셋으로 월별 12개씩 총 24개의 데이터셋 생성
#### - 이를 모두 concat 하여 대여소별로 뽑은 데이터로 딥러닝(LSTM) 진행

<br>
<br>
  
        
### ※대여소별 대여, 반납 예측 모형

### 1. 데이터 로드     
#### - 월별 12개의 대여, 반납 데이터     
#### - 모두 불러와 concat 뒤 미리 선정한 대여소 대여, 반납 데이터 추출       
    
<br>          
       
### 2. 전처리    
#### - 년, 월, 일, 시간 데이터는 datetime 형태로 다시 조합해 time 열 생성      
#### - time 열은 대여량과 함께 rent_df로 만들어 실제 수요와 예측량의 비교에 사용 예정     
#### - 요일 데이터는 범주형 데이터로 One-hot 형태로 새로운 열 생성
#### - 예측에 필요 없는 보관소명, 년, time, 요일 등의 행 삭제       
        
<br>           
       
### 3. 데이터 분리     
#### - train = 8, test = 2의 비율로 데이터셋 분리       
#### - 한 대여소 기준 총 행 8784개 = train(7027) + test(1757)    
       
<br>               
                 
### 4. 스케일링     
#### - RobustScaler 사용     
#### - 15개의 feature로 24시간의 데이터를 본 뒤 1시간 뒤를 예측하는 형태의 3차원 배열 구성      
       
<br>              
                 
### 5. 모델링 & 학습      
#### - 두 개의 LSTM Layer를 시작으로 unit이 1인 Dense Layer로 마무리     
#### - 손실함수는 MSE, optimizer는 Adam, 평가지표는 MAE 사용    
#### - earlystopping, checkpoint 설정     
#### - validation = 0.1 설정, 200 epochs, 32 batch size     
        
<br>         
                     
### 6. 시각화         
#### - train과 validation loss 값 추이      
![loss](https://user-images.githubusercontent.com/66204538/131249691-0546bd8e-285e-4ed7-837e-fba8a5d2018e.JPG)        
#### - 과거 대여 추이와 실제 대여량, 예측 대여량 그래프     
![KakaoTalk_20210827_1951392621111](https://user-images.githubusercontent.com/66204538/131250274-b9b0363e-dcbb-42e6-8e33-257358c2376f.png)

